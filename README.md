# Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles

## Overview
This repository contains the implementation of the methods described in "Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles" by Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. The paper introduces a non-Bayesian approach for predictive uncertainty estimation in neural networks, focusing on the use of deep ensembles for improved performance and calibration. Implementing different models such as CNNs with cross-entropy and Brier loss, adversarial training, and ensembles of CNNs. Creating a CNN model with MC-dropout and cross-entropy loss. The notebook outlines the training process and inference using MC dropout.

## Key Features
- Implementation of deep ensembles for uncertainty estimation.
- Methods for training neural networks to output predictive distributions.
- Use of proper scoring rules and adversarial training to enhance predictive uncertainty estimation.
- Empirical evaluation on various datasets including MNIST.

